{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk import word_tokenize\n",
    "import spacy\n",
    "from pymystem3 import Mystem\n",
    "m = Mystem()\n",
    "from nltk.corpus import stopwords\n",
    "from collections import Counter\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "nlp = spacy.load('ru_core_news_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordtok = nltk.tokenize.RegexpTokenizer('\\w+')\n",
    "\n",
    "with open ('1886 Скучная история .txt', 'r', encoding='windows-1251') as book1:\n",
    "    text1 = book1.read()\n",
    "words1 = wordtok.tokenize(text1)\n",
    "words1ful = word_tokenize(text1)\n",
    "with open ('1889 Лошадиная фамилия.txt', 'r', encoding='windows-1251') as book2:\n",
    "    text2 = book2.read()\n",
    "words2 = wordtok.tokenize(text2)\n",
    "words2ful = word_tokenize(text2)\n",
    "with open ('1896 Дом с мезонином.txt', 'r', encoding='windows-1251') as book3:\n",
    "    text3 = book3.read()\n",
    "words3 = wordtok.tokenize(text3)\n",
    "words3ful = word_tokenize(text3)\n",
    "with open ('1899 Дама с собачкой.txt', 'r', encoding='windows-1251') as book4:\n",
    "    text4 = book4.read()\n",
    "words4 = wordtok.tokenize(text4)\n",
    "words4ful = word_tokenize(text4)\n",
    "with open ('1900 Три сестры.txt', 'r', encoding='windows-1251') as book5:\n",
    "    text5 = book5.read()\n",
    "words5 = wordtok.tokenize(text5)\n",
    "words5ful = word_tokenize(text5)\n",
    "with open ('1904 Вишневый сад.txt', 'r', encoding='windows-1251') as book6:\n",
    "    text6 = book6.read()\n",
    "words6 = wordtok.tokenize(text6)\n",
    "words6ful = word_tokenize(text6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop = stopwords.words('russian')\n",
    "words1_filt = [word for word in words1 if word not in stop]\n",
    "words2_filt = [word for word in words2 if word not in stop]\n",
    "words3_filt = [word for word in words3 if word not in stop]\n",
    "words4_filt = [word for word in words4 if word not in stop]\n",
    "words5_filt = [word for word in words5 if word not in stop]\n",
    "words6_filt = [word for word in words6 if word not in stop]\n",
    "\n",
    "lemmatized_words1 = m.lemmatize(' '.join(words1_filt))\n",
    "lemmatized_words2 = m.lemmatize(' '.join(words2_filt))\n",
    "lemmatized_words3 = m.lemmatize(' '.join(words3_filt))\n",
    "lemmatized_words4 = m.lemmatize(' '.join(words4_filt))\n",
    "lemmatized_words5 = m.lemmatize(' '.join(words5_filt))\n",
    "lemmatized_words6 = m.lemmatize(' '.join(words6_filt))\n",
    "\n",
    "\n",
    "words1_filt_n = [word for word in lemmatized_words1 if word not in stop]\n",
    "words2_filt_n = [word for word in lemmatized_words2 if word not in stop]\n",
    "words3_filt_n = [word for word in lemmatized_words3 if word not in stop]\n",
    "words4_filt_n = [word for word in lemmatized_words4 if word not in stop]\n",
    "words5_filt_n = [word for word in lemmatized_words5 if word not in stop]\n",
    "words6_filt_n = [word for word in lemmatized_words6 if word not in stop]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Косинусное сходство текста 1 с текстом 2: 0.16075384241346902\n",
      "Косинусное сходство текста 1 с текстом 3: 0.4626378193006715\n",
      "Косинусное сходство текста 1 с текстом 4: 0.4236725553733015\n",
      "Косинусное сходство текста 1 с текстом 5: 0.27127007737928044\n",
      "Косинусное сходство текста 1 с текстом 6: 0.23608979092702986\n",
      "............................................................\n",
      "Косинусное сходство текста 2 с текстом 1: 0.16075384241346902\n",
      "Косинусное сходство текста 2 с текстом 3: 0.1316322507230134\n",
      "Косинусное сходство текста 2 с текстом 4: 0.11322309021336889\n",
      "Косинусное сходство текста 2 с текстом 5: 0.08836473580716875\n",
      "Косинусное сходство текста 2 с текстом 6: 0.07416705889723317\n",
      "............................................................\n",
      "Косинусное сходство текста 3 с текстом 1: 0.4626378193006715\n",
      "Косинусное сходство текста 3 с текстом 2: 0.1316322507230134\n",
      "Косинусное сходство текста 3 с текстом 4: 0.35837175093185214\n",
      "Косинусное сходство текста 3 с текстом 5: 0.21440067245638664\n",
      "Косинусное сходство текста 3 с текстом 6: 0.18666408835825773\n",
      "............................................................\n",
      "Косинусное сходство текста 4 с текстом 1: 0.4236725553733015\n",
      "Косинусное сходство текста 4 с текстом 2: 0.11322309021336889\n",
      "Косинусное сходство текста 4 с текстом 3: 0.35837175093185214\n",
      "Косинусное сходство текста 4 с текстом 5: 0.2204996317612973\n",
      "Косинусное сходство текста 4 с текстом 6: 0.1825868521308414\n",
      "............................................................\n",
      "Косинусное сходство текста 5 с текстом 1: 0.27127007737928044\n",
      "Косинусное сходство текста 5 с текстом 2: 0.08836473580716875\n",
      "Косинусное сходство текста 5 с текстом 3: 0.21440067245638664\n",
      "Косинусное сходство текста 5 с текстом 4: 0.2204996317612973\n",
      "Косинусное сходство текста 5 с текстом 6: 0.16412218422063446\n",
      "............................................................\n",
      "Косинусное сходство текста 6 с текстом 1: 0.23608979092702986\n",
      "Косинусное сходство текста 6 с текстом 2: 0.07416705889723317\n",
      "Косинусное сходство текста 6 с текстом 3: 0.18666408835825773\n",
      "Косинусное сходство текста 6 с текстом 4: 0.1825868521308414\n",
      "Косинусное сходство текста 6 с текстом 5: 0.16412218422063446\n",
      "............................................................\n"
     ]
    }
   ],
   "source": [
    "texts = [\n",
    "    \" \".join(words1_filt_n),\n",
    "    \" \".join(words2_filt_n),\n",
    "    \" \".join(words3_filt_n),\n",
    "    \" \".join(words4_filt_n),\n",
    "    \" \".join(words5_filt_n),\n",
    "    \" \".join(words6_filt_n)\n",
    "]\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(texts)\n",
    "cosine_similarities = cosine_similarity(tfidf_matrix, tfidf_matrix)\n",
    "\n",
    "cosine_similarities = cosine_similarity(tfidf_matrix)\n",
    "for i in range(len(texts)):\n",
    "    for j in range(len(texts)):\n",
    "        if j != i:\n",
    "            print(f\"Косинусное сходство текста {i + 1} с текстом {j + 1}: {cosine_similarities[i][j]}\")\n",
    "    print('.'*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
